{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'acme_gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-087fb4f778e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msolve_continuous_are\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macme_gym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#These are the functions from Brooke's Inverted Pendulum lab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'acme_gym'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import root\n",
    "from scipy.integrate import odeint\n",
    "from scipy.linalg import solve_continuous_are as scare\n",
    "import gym, acme_gym\n",
    "\n",
    "#These are the functions from Brooke's Inverted Pendulum lab\n",
    "def linearized_init(M, m, l, q1, q2, q3, q4, r):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ----------\n",
    "    M, m: floats\n",
    "    masses of the rickshaw and the present\n",
    "    l   : float\n",
    "    length of the rod\n",
    "    q1, q2, q3, q4, r : floats\n",
    "    relative weights of the position and velocity of the rickshaw, \n",
    "    the angular displacement theta and the change in theta, and the control\n",
    "    Return\n",
    "    -------\n",
    "    A : ndarray of shape (4,4)\n",
    "    B : ndarray of shape (4,1)\n",
    "    Q : ndarray of shape (4,4)\n",
    "    R : ndarray of shape (1,1)\n",
    "    '''\n",
    "    g = 9.8\n",
    "    A = np.zeros((4,4))\n",
    "    A[0,1] = 1\n",
    "    A[1,2] = m*g/M\n",
    "    A[2,3] = 1\n",
    "    A[3,2] = g/(M*l)*(M+m)\n",
    "    B = np.zeros((4,1))\n",
    "    B[1] = 1/M\n",
    "    B[3] = 1/(M*l)\n",
    "    Q = np.diag([q1, q2, q3, q4])\n",
    "    R = np.array([[r]])\n",
    "    return A, B, Q, R\n",
    "\n",
    "def find_P(A, B, Q, R):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ----------\n",
    "    A, Q    : ndarrays of shape (4,4)\n",
    "    B       : ndarray of shape (4,1)\n",
    "    R       : ndarray of shape (1,1)\n",
    "    Returns\n",
    "    -------\n",
    "    P       : the matrix solution of the Riccati equation\n",
    "    '''\n",
    "    def fun(P):\n",
    "        P = P.reshape((4,4))\n",
    "        root = P@A+A.T@P+Q-1/R[0]*(P@B@B.T@P)\n",
    "        return root.reshape(16)\n",
    "    P0 = np.ones(16)\n",
    "    P = root(fun,P0).x.reshape((4,4))\n",
    "    return P\n",
    "\n",
    "def rickshaw(tv, X0, A, B, Q, R, P):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ----------\n",
    "    tv  : ndarray of time values, with shape (n+1,)\n",
    "    X0  : Initial conditions on state variables\n",
    "    A, Q: ndarrays of shape (4,4)\n",
    "    B   : ndarray of shape (4,1)\n",
    "    R   : ndarray of shape (1,1)\n",
    "    P   : ndarray of shape (4,4)\n",
    "    Returns\n",
    "    -------\n",
    "    Z : ndarray of shape (n+1,4), the state vector at each time\n",
    "    U : ndarray of shape (n+1,), the control values\n",
    "    '''\n",
    "    \n",
    "    func = lambda z,t: (A - 1/R[0]*B@B.T@P)@z.T\n",
    "    Z = odeint(func, X0, tv)\n",
    "    BP = B.T@P\n",
    "    U = -1/R[0]*(BP)@Z.T\n",
    "    return Z,U  \n",
    "\n",
    "def stabilize(M, m, l, q1, q2, q3, q4, r, X0, tf, step):\n",
    "    A, B, Q, R = linearized_init(M, m, l, q1, q2, q3, q4, r)\n",
    "    P = scare(A, B, Q, R)\n",
    "    tv = np.linspace(0,tf,step)\n",
    "    Z, U = rickshaw(tv,X0,A, B, Q, R, P)\n",
    "    #Z is state vector\n",
    "    #U is control values\n",
    "    return Z,U\n",
    "    \n",
    "def cartpole(environment, init_state, tol=1e-2, disp=False, N = 300):\n",
    "    env = environment\n",
    "    obs = init_state\n",
    "    \n",
    "    control = []\n",
    "    \n",
    "    '''\n",
    "    This function will run the cartpole problem using the environment and initial conditions provided.\n",
    "    Do NOT call env.reset().\n",
    "    Run whatever system you desire to make sure the state values fall under the tolerance level.\n",
    "    Convergence is considered reached once numpy.linalg.norm(obs[1:]) < tol, where we ignore the x position of the cart.\n",
    "    You will need to return the sequence of controls that brings the cartpole system into vertical stability.\n",
    "    Make sure to quit after N iterations, or convergence is reached, whichever occurs first.\n",
    "    Remember you are being graded against other teams' step counts, so you want to end the system updates as soon as possible.\n",
    "    \n",
    "    Parameters:\n",
    "        environment (CartPole object): The cartpole environment as described in gym and acme_gym.\n",
    "        init_state (tuple): The initial state with [x, x', θ, θ'].\n",
    "        tol (float): The tolerance to be reached before the cartpole problem is considered converged.\n",
    "        disp (bool): If True, render the image.\n",
    "        N (int): The max number of iterations.\n",
    "    \n",
    "    Returns:\n",
    "        (list): A list of control values. These will be tested on the grader's end for convergence and time step assessment.\n",
    "    \n",
    "    '''\n",
    "    env = gym.make('CartPoleContinuous-v0')\n",
    "    T = round(6/0.02)\n",
    "    # Initial state is drawn randomly, let the user pick a good starting point\n",
    "    init_state = True\n",
    "    if init_state:\n",
    "        obs = env.reset()\n",
    "        env.render()\n",
    "        \n",
    "    step = 500\n",
    "    x0 = obs\n",
    "    q1, q2, q3, q4 = 90000., 1., 90000., 1\n",
    "    tf = .02*step\n",
    "    r = 10. # Weight on the control, how do we know what it should be?\n",
    "    M, m, l = 1, .1, 1\n",
    "    Z, U = stabilize(M, m, l, q1, q2, q3, q4, r, x0, tf, step)\n",
    "    U = U.T\n",
    "\n",
    "    for i in range(step):\n",
    "        #get a new obs every interation... are we supposed to include that in new calcs?\n",
    "        control.append(U[0])\n",
    "        obs, reward, state, info = env.step(np.array(U[0]))\n",
    "        env.render()\n",
    "\n",
    "        # Feedback\n",
    "        x0 = np.array([obs[0],obs[1],-obs[2],-obs[3]])\n",
    "        Z, U = stabilize(M, m, l, q1, q2, q3, q4, r, x0, tf, step)\n",
    "        U = U.T\n",
    "    \n",
    "    env.close()\n",
    "    return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, acme_gym\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy import linalg\n",
    "from tqdm import tqdm\n",
    "\n",
    "tol = 1e-2\n",
    "total = 200\n",
    "\n",
    "render = True\n",
    "\n",
    "num_steps = []\n",
    "\n",
    "for i in tqdm(range(total)):\n",
    "    env = gym.make(\"CartPoleContinuous-v0\")\n",
    "    observation = env.reset()\n",
    "    env_copy = copy.deepcopy(env)\n",
    "    \n",
    "    # This is students' code\n",
    "    control = cartpole(env_copy, observation, tol, render)\n",
    "    \n",
    "    for u in control:\n",
    "        obs, reward, state, info = env.step(np.array([u]))\n",
    "        \n",
    "        if render:\n",
    "            env.render()\n",
    "    \n",
    "    render = False\n",
    "    \n",
    "    if np.linalg.norm(obs[1:]) > tol:\n",
    "        print(\"unsuccessful\")\n",
    "    \n",
    "    num_steps.append(len(control))\n",
    "    env.close()\n",
    "\n",
    "print(\"Average number of steps after {} iterations: {}\".format(total, np.mean(num_steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
